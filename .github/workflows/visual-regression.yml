# Visual Regression Testing Workflow
#
# This workflow runs visual regression tests for design-toolkit components
# when changes are made to relevant packages. It generates screenshots and
# compares them against baselines, posting a summary comment on pull requests.
#
# The workflow:
# 1. Builds the @apps/next application
# 2. Runs Vitest browser tests that capture screenshots
# 3. Compares screenshots against committed baselines
# 4. Posts results as a PR comment

name: Visual Regression Tests

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - "packages/design-toolkit/**"
      - "packages/design-foundation/**"
      - "apps/next/**"
      - ".github/workflows/visual-regression.yml"

permissions:
  contents: read
  pull-requests: write

env:
  TURBO_TELEMETRY_DISABLED: 1

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number }}
  cancel-in-progress: true

jobs:
  visual-regression:
    name: Visual Regression
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Cache Turbo
        uses: actions/cache@v4
        with:
          path: .turbo
          key: ${{ runner.os }}-turbo-visual-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-turbo-visual-
            ${{ runner.os }}-turbo-

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          run_install: false

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          cache: "pnpm"
          node-version-file: "package.json"

      - name: Install dependencies
        run: pnpm install

      - name: Build packages
        run: pnpm run build

      - name: Install Playwright Chromium
        run: pnpm exec playwright install chromium
        working-directory: apps/next

      - name: Run Visual Regression Tests
        id: visual-tests
        run: |
          pnpm visual --reporter=default --reporter=json --outputFile=test-results.json || TEST_EXIT_CODE=$?
          TEST_EXIT_CODE=${TEST_EXIT_CODE:-0}

          # Parse test counts from JSON output
          PASSED=$(jq -r '.numPassedTests // 0' test-results.json)
          FAILED=$(jq -r '.numFailedTests // 0' test-results.json)

          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "exit_code=$TEST_EXIT_CODE" >> $GITHUB_OUTPUT

          exit $TEST_EXIT_CODE
        working-directory: apps/next
        continue-on-error: true

      - name: Parse VRT Failures
        id: parse-failures
        if: steps.visual-tests.outputs.exit_code != '0'
        run: |
          FAILURES_JSON=$(node .github/scripts/parse-vrt-failures.mjs apps/next/test-results.json)
          echo "json<<EOF" >> $GITHUB_OUTPUT
          echo "$FAILURES_JSON" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Upload Screenshot Diffs
        uses: actions/upload-artifact@v4
        if: steps.visual-tests.outputs.exit_code != '0'
        with:
          name: screenshot-diffs
          path: apps/next/src/features/**/__screenshots__/
          retention-days: 30

      - name: Generate VRT Coverage Report
        id: vrt-coverage
        run: |
          COVERAGE_JSON=$(node .github/scripts/vrt-coverage.mjs)
          echo "json<<EOF" >> $GITHUB_OUTPUT
          echo "$COVERAGE_JSON" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Post PR Comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        env:
          COVERAGE_JSON: ${{ steps.vrt-coverage.outputs.json }}
          FAILURES_JSON: ${{ steps.parse-failures.outputs.json }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const passed = parseInt('${{ steps.visual-tests.outputs.passed }}') || 0;
            const failed = parseInt('${{ steps.visual-tests.outputs.failed }}') || 0;
            const exitCode = '${{ steps.visual-tests.outputs.exit_code }}';
            const total = passed + failed;

            // Parse VRT coverage data
            const coverageJson = process.env.COVERAGE_JSON || '';
            let coverage = null;
            try {
              if (coverageJson) {
                coverage = JSON.parse(coverageJson);
              }
            } catch (e) {
              console.log('Failed to parse coverage JSON:', e);
            }

            // Parse VRT failures data
            const failuresJson = process.env.FAILURES_JSON || '';
            let failuresData = null;
            try {
              if (failuresJson) {
                failuresData = JSON.parse(failuresJson);
              }
            } catch (e) {
              console.log('Failed to parse failures JSON:', e);
            }

            const status = exitCode === '0'
              ? '‚úÖ All tests passed'
              : failed > 0
                ? '‚ùå Some tests failed'
                : '‚ö†Ô∏è Tests did not complete';

            // Get the current job's URL for direct linking to test output
            const { data: jobs } = await github.rest.actions.listJobsForWorkflowRun({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: parseInt(process.env.GITHUB_RUN_ID),
            });
            const currentJob = jobs.jobs.find(job => job.name === 'Visual Regression');
            const testStep = currentJob?.steps?.find(step => step.name === 'Run Visual Regression Tests');
            const stepAnchor = testStep ? `#step:${testStep.number}:1` : '';
            const jobUrl = (currentJob?.html_url || `${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID}`) + stepAnchor;

            // Get artifact download URL (only when tests fail)
            let artifactUrl = '';
            let artifactError = false;
            if (failed > 0) {
              try {
                const { data: artifacts } = await github.rest.actions.listWorkflowRunArtifacts({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  run_id: parseInt(process.env.GITHUB_RUN_ID),
                });
                const screenshotArtifact = artifacts.artifacts.find(a => a.name === 'screenshot-diffs');
                if (screenshotArtifact) {
                  artifactUrl = `${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID}/artifacts/${screenshotArtifact.id}`;
                }
              } catch (e) {
                console.log('Failed to get artifact URL:', e);
                artifactError = true;
              }
            }

            // Build download link with fallback for errors
            let downloadLink = '';
            if (artifactUrl) {
              downloadLink = ` | **[Download screenshots](${artifactUrl})**`;
            } else if (artifactError) {
              downloadLink = ' | _Screenshot artifacts uploaded (link unavailable)_';
            }

            // Build failed tests section
            let failedTestsSection = '';
            if (failuresData && failuresData.failures && failuresData.failures.length > 0) {
              // Build simple list of all failing test names
              const testNames = failuresData.failures.map(f => `- ${f.fullName}`).join('\n');
              const count = failuresData.failures.length;

              failedTestsSection = [
                '',
                '### ‚ùå Failed Tests',
                '',
                `**[View full test output](${jobUrl})**${downloadLink}`,
                '',
                '<details>',
                `<summary>${count} failing test${count === 1 ? '' : 's'}</summary>`,
                '',
                testNames,
                '',
                '</details>',
              ].join('\n');
            } else if (failed > 0) {
              // Fallback when parsing failed but we know tests failed
              failedTestsSection = [
                '',
                '### ‚ùå Failed Tests',
                '',
                `**[View full test output](${jobUrl})**${downloadLink}`,
                '',
                '> ‚ö†Ô∏è Failed to parse test details. Check the workflow logs for specifics.',
              ].join('\n');
            }

            // Build update instructions (only shown when tests fail)
            const updateInstructions = failed > 0 ? [
              '',
              '### üîÑ Update Snapshots',
              '',
              'If these visual changes are intentional, update the baselines:',
              '',
              `1. Go to **[Actions ‚Üí Update Visual Regression Snapshots](${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/actions/workflows/visual-regression-update.yml)**`,
              `2. Click **"Run workflow"**`,
              `3. Select branch: \`${{ github.head_ref }}\``,
              `4. Click **"Run workflow"** to update and commit new baselines`,
            ].join('\n') : '';

            // Build coverage section
            let coverageSection = '';
            if (coverage) {
              const missingList = coverage.missingComponents.length > 0
                ? coverage.missingComponents.map(c => `- ${c}`).join('\n')
                : 'None';

              coverageSection = [
                '',
                '### Component Coverage',
                '',
                `**${coverage.covered} / ${coverage.total}** design-toolkit components have VRT tests (${coverage.percentage}%)`,
                '',
                `<details><summary>Missing VRT tests (${coverage.missing} components)</summary>`,
                '',
                missingList,
                '',
                '</details>',
                '',
                coverage.excludedComponents.length > 0
                  ? `> ${coverage.excluded} components excluded: ${coverage.excludedComponents.join(', ')}`
                  : '',
              ].filter(Boolean).join('\n');
            }

            const body = [
              '## üñºÔ∏è Visual Regression Test Results',
              '',
              `**Status:** ${status}`,
              '',
              '| Metric | Count |',
              '|--------|-------|',
              `| ‚úÖ Passed | ${passed} |`,
              `| ‚ùå Failed | ${failed} |`,
              `| **Total** | ${total} |`,
              failedTestsSection,
              updateInstructions,
              coverageSection,
              '',
              '---',
              '<sub>ü§ñ Generated by Vitest Browser + Playwright</sub>',
            ].filter(Boolean).join('\n');

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('Visual Regression Test Results')
            );

            if (botComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body
              });
            }

      - name: Fail if tests failed
        if: steps.visual-tests.outputs.exit_code != '0'
        env:
          FAILURES_JSON: ${{ steps.parse-failures.outputs.json }}
        run: |
          echo "‚ùå Visual regression tests failed"
          echo ""
          echo "Failing tests:"
          echo "$FAILURES_JSON" | jq -r '.failures[].fullName' | while read -r name; do
            echo "  - $name"
          done
          echo ""
          exit 1
