# Visual Regression Testing Workflow
#
# This workflow runs visual regression tests for design-toolkit components
# when changes are made to relevant packages. It generates screenshots and
# compares them against baselines, posting a summary comment on pull requests.
#
# The workflow:
# 1. Builds the @apps/next application
# 2. Runs Vitest browser tests that capture screenshots
# 3. Compares screenshots against committed baselines
# 4. Posts results as a PR comment

name: Visual Regression Tests

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - 'packages/design-toolkit/**'
      - 'packages/design-foundation/**'
      - 'apps/next/**'
      - '.github/workflows/visual-regression.yml'

permissions:
  contents: read
  pull-requests: write

env:
  TURBO_TELEMETRY_DISABLED: 1

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number }}
  cancel-in-progress: true

jobs:
  visual-regression:
    name: Visual Regression
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Cache Turbo
        uses: actions/cache@v4
        with:
          path: .turbo
          key: ${{ runner.os }}-turbo-visual-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-turbo-visual-
            ${{ runner.os }}-turbo-

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          run_install: false

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          cache: 'pnpm'
          node-version-file: 'package.json'

      - name: Install dependencies
        run: pnpm install

      - name: Build packages
        run: pnpm run build

      - name: Install Playwright Chromium
        run: pnpm exec playwright install chromium
        working-directory: apps/next

      - name: Run Visual Regression Tests
        id: visual-tests
        run: |
          pnpm visual 2>&1 | tee test-output.txt
          TEST_EXIT_CODE=${PIPESTATUS[0]}

          # Count passed/failed tests from output
          PASSED=$(grep -oP '\d+(?= passed)' test-output.txt | tail -1 || echo "0")
          FAILED=$(grep -oP '\d+(?= failed)' test-output.txt | tail -1 || echo "0")

          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "exit_code=$TEST_EXIT_CODE" >> $GITHUB_OUTPUT

          exit $TEST_EXIT_CODE
        working-directory: apps/next
        continue-on-error: true

      - name: Upload Screenshot Diffs
        uses: actions/upload-artifact@v4
        if: steps.visual-tests.outputs.exit_code != '0'
        with:
          name: screenshot-diffs
          path: apps/next/src/features/**/__screenshots__/
          retention-days: 30

      - name: Post PR Comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const passed = parseInt('${{ steps.visual-tests.outputs.passed }}') || 0;
            const failed = parseInt('${{ steps.visual-tests.outputs.failed }}') || 0;
            const exitCode = '${{ steps.visual-tests.outputs.exit_code }}';
            const total = passed + failed;

            const status = exitCode === '0'
              ? 'âœ… All tests passed'
              : failed > 0
                ? 'âŒ Some tests failed'
                : 'âš ï¸ Tests did not complete';

            const body = [
              '## ğŸ–¼ï¸ Visual Regression Test Results',
              '',
              `**Status:** ${status}`,
              '',
              '| Metric | Count |',
              '|--------|-------|',
              `| âœ… Passed | ${passed} |`,
              `| âŒ Failed | ${failed} |`,
              `| **Total** | ${total} |`,
              '',
              '<details><summary>ğŸ“‹ Details</summary>',
              '',
              `- **Workflow run:** [View details](${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID})`,
              failed > 0 ? '- **Screenshot diffs:** Available in workflow artifacts' : '',
              '',
              '</details>',
              '',
              '---',
              '<sub>ğŸ¤– Generated by Vitest Browser + Playwright</sub>',
            ].filter(Boolean).join('\n');

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('Visual Regression Test Results')
            );

            if (botComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body
              });
            }

      - name: Fail if tests failed
        if: steps.visual-tests.outputs.exit_code != '0'
        run: exit 1
